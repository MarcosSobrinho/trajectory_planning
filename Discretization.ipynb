{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization\n",
    "\n",
    "In this notebook I describe how to translate the mathematical basics into a form, that makes numeric programming possible. This requires discretization in time. For further details I recommend [Trajectory Planning for BERTHA - a Local, Continuous Method](https://pdfs.semanticscholar.org/bdca/7fe83f8444bb4e75402a417053519758d36b.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization of the kinematic model\n",
    "\n",
    "First of all the function $s(t)$ has to be discretized to a sequence in which $s_{i}$ describe the value of $s$ during discrete moments $i$. These moments are equidistant in time. The distance between adjacent points in time is $\\Delta t = \\frac{T}{N-1}$, where $T$ is the optimization timespan and $N$ is the desired number of points. These numbers may be chosen freely. I use $ T = 10 s$ and $ N = 30 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the discretization the velocity, accelleration and jerk cannot be computed as derivates of $s$. They have to be adjusted to finite differences:\n",
    "\n",
    "$$ v_{i} \\approx \\frac{s_{i+1} - s_{i}}{\\Delta t} \\quad i = 0,...,N-1 $$\n",
    "-\n",
    "$$ a_{i} \\approx \\frac{v_{i+1} - v_{i}}{\\Delta t} \\quad i = 0,...,N-2 $$\n",
    "-\n",
    "$$ j_{i} \\approx \\frac{a_{i+1} - a_{i}}{\\Delta t} \\quad i = 0,...,N-3 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 10\n",
    "N = 30\n",
    "\n",
    "del_t = T/(N-1)\n",
    "\n",
    "# Velocity\n",
    "def v(x):\n",
    "    \n",
    "    v = np.zeros(N - 1)\n",
    "    v = (x[1:] - x[:-1])/del_t\n",
    "    return v\n",
    "\n",
    "# Accelleration\n",
    "def a(x):\n",
    "    v1 = v(x)\n",
    "    \n",
    "    a = np.zeros(N - 2)\n",
    "    a = (v1[1:] - v1[:-1])/del_t\n",
    "    return a\n",
    "\n",
    "# Jerk\n",
    "def j(x):\n",
    "    a1 = a(x)\n",
    "    \n",
    "    j = np.zeros(N - 3)\n",
    "    j = (a1[1:] - a1[:-1])/del_t\n",
    "    return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization of the cost functional\n",
    "\n",
    "Due to the discretization of $s$ the argument of the cost functional\n",
    "\n",
    "$$ J(s(t)) = \\frac{1}{2} \\int_{t}^{t+T} w_{v}(v(t) - v_{des})^{2} + w_{a}a(t)^{2} + w_{j}j(t)^{2} dt $$\n",
    "\n",
    "\n",
    "is not a function in time, but a sequence. This means that the cost functional is simplified to the cost function\n",
    "\n",
    "$$ J(s_{0},...,s_{N-1}) = \\frac{1}{2} \\left ( w_{v}\\sum_{i=0}^{N-1} (v_{i} - v_{des})^{2} + w_{a}\\sum_{i=0}^{N-2} a_{i}^{2} + w_{j}\\sum_{i=0}^{N-3} j_{i}^{2} \\right ) \\Delta t. $$\n",
    "\n",
    "The integral can be simplified to a sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def J(x):\n",
    "    return 0.5*(sum((v(x) - v_des)**2) + sum(a(x)**2) + sum(j(x)**2))*del_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Constraints\n",
    "\n",
    "The phyiscal constraints \n",
    "\n",
    "$$ v(t) \\le v_{max}, $$\n",
    "-\n",
    "$$ a(t) \\le a_{max}. $$\n",
    "\n",
    "are added to the optimizer as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_max = 30\n",
    "a_max = 15\n",
    "\n",
    "def cons_vel(x):\n",
    "    return v_max - v(x)\n",
    "\n",
    "def cons_acc(x):\n",
    "    return a_max - a(x)\n",
    "\n",
    "def pos_ves(x):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bound Constraints\n",
    "\n",
    "Since the cost function $J(s_{0},...,s_{N-1})$ is only proportional to derivations of $s$, but not to $s$ itself, the optimization will lead a trajectory that is located arbitrarilly. To prevent this, bound constraints are used to fixate the trajectories location. Furthermore, the trajectories first points are predetermined because of the self driving cars location, velocity and accelleration. \n",
    "\n",
    "In general, bound contraints are used to limit each optimization variable. In this case $N$ bound constraints are needed, because the optimization problem contains $N$ optimization variables $s_{i}$ with $i = 0,..., N-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vel_init = 0\n",
    "acc_init = 0\n",
    "\n",
    "bounds = [(0, np.inf) for i in range(N)]\n",
    "bounds[0] = (0, 0)\n",
    "bounds[1] = (vel_init * del_t, vel_init * del_t)\n",
    "bounds[2] = (acc_init * del_t ** 2 + 2 * vel_init * del_t, acc_init * del_t ** 2 + 2 * vel_init * del_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided information already suffices to compute a trajectory without obstacles. An initialization is required for the optimizer. It can be chosen randomly. The desired velocity $v_{des}$ is provided as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_0 = np.arange(30)\n",
    "v_des = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 420.523805194\n",
      "            Iterations: 36\n",
      "            Function evaluations: 1233\n",
      "            Gradient evaluations: 36\n"
     ]
    }
   ],
   "source": [
    "no_obstacles_res = minimize(J, x_0, method='SLSQP', bounds = bounds, options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_axis = np.linspace(0, 10, N)\n",
    "\n",
    "plt.plot(t_axis, no_obstacles_res.x)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the result of the optimization in a plot, run all the cells of the notebook upto this point!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obstacles\n",
    "\n",
    "![](img/small.png)\n",
    "\n",
    "Obstacles, like the red car in the image above are also represented in the bound constraints. To be precise, the linear constraints \n",
    "\n",
    "$$ s(t) \\ge s_{b}, \\quad \\in [t_{a}, t_{b}], $$\n",
    "-\n",
    "$$ s(t) \\le s_{a}, \\quad \\in [t_{a}, t_{b}], $$\n",
    "\n",
    "are transformed to \n",
    "\n",
    "$$ s_{i} \\ge s_{b}, \\quad i = t_{a},..., t_{b}, $$\n",
    "-\n",
    "$$ s_{i} \\le s_{a}, \\quad i = t_{a},..., t_{b}. $$\n",
    "\n",
    "Because both equations describe different convex spaces, two optimizations have to be performed (one with each equation worked into the bound constraints). The implementation details will follow..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
